#MODEL_NAME="gpt-4o-mini"
MODEL_TYPE="OpenAI" # if use the gpt series (OpenAI), lamma series (LLAMA)
OPENAI_API_KEY=""
#OPENAI_API_KEY=""
#OPENAI_ORGANIZATION="OpenAI"
# API_BASE_URL="http://127.0.0.1:8079" # turn it on if using a VPN
OPENAI_BASE_URL="https://xiaoai.plus/v1"
MODEL_NAME="claude-3-5-sonnet-20241022"
# BING_SUBSCRIPTION_KEY=""
# BING_SEARCH_URL="https://api.bing.microsoft.com/v7.0/search"
# WOLFRAMALPHA_APP_ID=""

# LLAMA in local server
# open llama3 at local server
# curl -fsSL https://ollama.com/install.sh | sh
# ollama run llama3
# export NO_PROXY=localhost,127.0.0.1 
# MODEL_NAME="llama3"
# MODEL_TYPE="OLLAMA"
# EMBED_MODEL_TYPE="OLLAMA"
# EMBED_MODEL_NAME="nomic-embed-text"
# MODEL_SERVER="http://localhost:11434" # only for local model

#MODEL_NAME="gpt-4o"
#MODEL_TYPE="OpenAI" # if use the gpt series (OpenAI), lamma series (LLAMA)
OPENAI_EMBED_API_KEY=""
OPENAI_ORGANIZATION=""
OPENAI_EMBED_BASE_URL="https://xiaoai.plus/v1"